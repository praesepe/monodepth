{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1)\n",
    "        self.elu = nn.ELU()\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.shortcut = nn.Sequential(nn.Conv2d(inplanes, self.expansion*planes, kernel_size=1, stride=stride))\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.elu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.elu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        out += self.shortcut(x)\n",
    "        out = self.elu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, mid, stride=1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(mid, planes, kernel_size=3, stride=1, padding=1)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, x, skip, udisp=None):\n",
    "        x = self.upsample(x)\n",
    "        x = self.elu(self.conv1(x))\n",
    "        #concat\n",
    "        if udisp is not None:\n",
    "            x = torch.cat((x, skip, udisp), 1)\n",
    "        else:\n",
    "            x = torch.cat((x, skip), 1)\n",
    "        x = self.elu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DispBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, inplanes, planes=2, kernel=3, stride=1):\n",
    "        super(DispBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, 2, kernel_size=kernel, stride=stride, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.conv2 = nn.Conv2d(2, 1, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        #self.conv2.weight.requires_grad = False\n",
    "        #self.conv2.weight.data = torch.cuda.FloatTensor([1,0]).view(1,2,1,1)\n",
    "        self.conv3 = nn.Conv2d(2, 1, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        #self.conv3.weight.requires_grad = False\n",
    "        #self.conv3.weight.data = torch.cuda.FloatTensor([0,1]).view(1,2,1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        disp = 0.3 * self.sigmoid(self.conv1(x))\n",
    "        udisp = self.upsample(disp)\n",
    "        #out = torch.cat((disp[:,0,:,:].unsqueeze(1) * x.shape[3], disp[:,1,:,:].unsqueeze(1) * x.shape[2]), 1)\n",
    "        #tmp = Variable(torch.zeros(disp.shape[0], 1, disp.shape[2], disp.shape[3]).cuda())\n",
    "        #left_est = disp[:,0,:,:].unsqueeze(1).contiguous()\n",
    "        #right_est = disp[:,1,:,:].unsqueeze(1).contiguous()\n",
    "        self.conv2.weight.data = torch.cuda.FloatTensor([1,0]).view(1,2,1,1)\n",
    "        self.conv3.weight.data = torch.cuda.FloatTensor([0,1]).view(1,2,1,1)\n",
    "        left_est = self.conv2(disp)\n",
    "        right_est = self.conv3(disp)\n",
    "        return left_est, right_est, udisp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonodepthNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=Bottleneck, layers=[3, 4, 6, 3], num_classes=1000, do_stereo = 0):\n",
    "        self.inplanes = 64\n",
    "        super(MonodepthNet, self).__init__()\n",
    "        if do_stereo:\n",
    "            self.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.elu = nn.ELU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.up6 = DecoderBlock(2048, 512, 1536)\n",
    "        self.up5 = DecoderBlock(512, 256, 768)\n",
    "        self.up4 = DecoderBlock(256, 128, 384)\n",
    "        self.get_disp4 = DispBlock(128)\n",
    "        self.up3 = DecoderBlock(128, 64, 130)\n",
    "        self.get_disp3 = DispBlock(64)\n",
    "        self.up2 = DecoderBlock(64, 32, 98)\n",
    "        self.get_disp2 = DispBlock(32)\n",
    "        self.up1 = DecoderBlock(32, 16, 18)\n",
    "        self.get_disp1 = DispBlock(16)\n",
    "                \n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, 1))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks - 1):\n",
    "            layers.append(block(self.inplanes, planes, 1))\n",
    "        layers.append(block(self.inplanes, planes, 2))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #encoder\n",
    "        x = self.conv1(x) #2\n",
    "        conv1 = self.elu(x)\n",
    "        pool1 = self.maxpool(conv1) #4\n",
    "        conv2 = self.layer1(pool1) #8\n",
    "        conv3 = self.layer2(conv2) #16\n",
    "        conv4 = self.layer3(conv3) #32\n",
    "        conv5 = self.layer4(conv4) #64\n",
    "        \n",
    "        #skip\n",
    "        skip1 = conv1\n",
    "        skip2 = pool1\n",
    "        skip3 = conv2\n",
    "        skip4 = conv3\n",
    "        skip5 = conv4\n",
    "        \n",
    "        #decoder\n",
    "        upconv6 = self.up6(conv5, skip5)\n",
    "        upconv5 = self.up5(upconv6, skip4)\n",
    "        upconv4 = self.up4(upconv5, skip3)\n",
    "        #self.disp4, udisp4 = self.get_disp4(upconv4)\n",
    "        self.disp4_left, self.disp4_right, udisp4 = self.get_disp4(upconv4)\n",
    "\n",
    "        upconv3 = self.up3(upconv4, skip2, udisp4)\n",
    "        #self.disp3, udisp3 = self.get_disp3(upconv3)\n",
    "        self.disp3_left, self.disp3_right, udisp3 = self.get_disp3(upconv3)\n",
    "\n",
    "        upconv2 = self.up2(upconv3, skip1, udisp3)\n",
    "        #self.disp2, udisp2 = self.get_disp2(upconv2)\n",
    "        self.disp2_left, self.disp2_right, udisp2 = self.get_disp2(upconv2)\n",
    "\n",
    "        upconv1 = self.up1(upconv2, udisp2)\n",
    "        #self.disp1, udisp1 = self.get_disp1(upconv1)\n",
    "        self.disp1_left, self.disp1_right, udisp1 = self.get_disp1(upconv1)\n",
    "        \n",
    "        return [self.disp1_left, self.disp2_left, self.disp3_left, self.disp4_left], [self.disp1_right, self.disp2_right, self.disp3_right, self.disp4_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
